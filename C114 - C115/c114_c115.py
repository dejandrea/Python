# -*- coding: utf-8 -*-
"""C114 - C115.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y3YSq9kQ8mMDs1NU9Dvmx8i0p5ZU5VEt

## Carregue o Conjunto de Dados

# Aula 114
"""

#Carregue o conjunto de dados do diretório fornecido
!git clone https://github.com/ByjusBrazil/PRO_1-1_C114_TextSentimentDataset

"""## Pandas:
O **Pandas** é uma biblioteca de código aberto construída sobre o Numpy e o Matplotlib. Ele fornece estruturas de dados de alto desempenho e fáceis de usar e ferramentas de análise de dados. 

Um DataFrame (quadro de dados) é uma estrutura de dados bidimensional, ou seja, os dados são alinhados de forma tabular em linhas e colunas da mesma forma que nosso conjunto de dados de teste. O DataFrame do Pandas consiste em três componentes principais, os dados, as linhas e as colunas.

O DataFrame do Pandas será criado carregando os conjuntos de dados de arquivos existentes do MS Excel, arquivos CSV ou banco de dados SQL. O DataFrame do Pandas também pode ser criado a partir de listas, dicionários, etc.

## Use o Pandas para exibir o conjunto de dados
"""

import pandas as pd

#leia o arquivo excel
train_data_raw = pd.read_excel("/content/PRO_1-1_C114_TextSentimentDataset/text-emotion-training-dataset.xlsx")

#exiba as primeiras cinco entradas do conjunto de dados de treinamento
train_data_raw.head()

"""## Divida as linhas em duas colunas: Texto e Emoção"""

# Divida as linhas em duas colunas: Texto e Emoção
train_data = pd.DataFrame(train_data_raw["Text_Emotion"].str.split(";",1).tolist(), 
                                                     columns = ['Texto','Emoção'])

train_data.head()

"""## Dando etiquetas às emoções"""

#Encontre emoções únicas
train_data["Emoção"].unique()

#Crie um dicionário para substituir emoções por etiquetas
encode_emotions = {"raiva": 0, "medo": 1, "alegria": 2, "amor": 3, "tristeza": 4, "surpresa": 5}

train_data.replace(encode_emotions, inplace = True)
train_data.head()

"""## Converta o Dataframe em uma lista de conjunto de dados"""

# Converta o Dataframe em uma lista de conjunto de dados

training_sentences = []
training_labels = []

# Anexe o texto e as emoções na lista usando o método 'loc'

for i in range(len(train_data)):
  
  sentence = train_data.loc[i, "Texto"]
  training_sentences.append(sentence)

  label = train_data.loc[i, "Emoção"]
  training_labels.append(label)

# Verifique um texto e uma etiqueta aleatórios da lista

training_sentences[20], training_labels[20]

"""## Tokenização e Preenchimento
O ato de converter texto em números é conhecido como **Tokenização**. A classe Tokenizer do Keras é usada para codificar entrada de texto em sequências inteiras.

"""

#importe o Tokenizer do tensorflow

import tensorflow as tf

from tensorflow.keras.preprocessing.text import Tokenizer

#Defina os parâmetros do Tokenizer

vocab_size = 10000
embedding_dim = 16
oov_tok = "<OOV>"
training_size = 20000

tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)
tokenizer.fit_on_texts(training_sentences)

#Crie um dicionário chamado word_index

word_index = tokenizer.word_index

#Verifique o valor numérico atribuído a uma palavra

word_index["o"]

training_sequences = tokenizer.texts_to_sequences(training_sentences)

print(training_sequences[0])
print(training_sequences[1])
print(training_sequences[2])

"""O **Preenchimento** é importante para fazer com que todas as frases contenham o mesmo número de palavras. Zeros são usados para preencher a sequência tokenizada para fazer o texto conter o mesmo número de tokens."""

#Defina os parâmetros das pad_sequences

from tensorflow.keras.preprocessing.sequence import pad_sequences

padding_type='post'
max_length = 100
trunc_type='post'


training_padded = pad_sequences(training_sequences, maxlen=max_length, 
                                padding=padding_type, truncating=trunc_type)

training_padded

"""# Aula 115

## Convertendo sequências e etiquetas preenchidas em um array Numpy
"""

#Crie arrays numpy para sequências e etiquetas preenchidas
import numpy as np

training_padded = np.array(training_padded)
training_labels = np.array(training_labels)

"""## Compilação do Modelo"""

#Defina diferentes camadas e compile o modelo

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
from tensorflow.keras.layers import Conv1D, Dropout, MaxPooling1D

model = tf.keras.Sequential([
    #Camada Embedding
    Embedding(vocab_size,embedding_dim,input_length = max_length),
    Dropout(0.2),

    #Camada Conv1D
    Conv1D(filters=256, kernel_size = 3, activation="relu"),
    MaxPooling1D(pool_size=3),

    #Camada Conv1D
    Conv1D(filters=128, kernel_size = 3, activation="relu"),
    MaxPooling1D(pool_size=3),

    #camada LSTM
    LSTM(128),

    #camada dense
    Dense(128,activation='relu'),
    Dropout(0.2),
    Dense(64,activation='relu'),
    Dense(6,activation='softmax'),

])

model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

"""## Resumo do Modelo"""

#use o método summary()
model.summary()

"""## Treine o Modelo"""

#use a função fit() para treinar o modelo
num_epochs = 30
history = model.fit(training_padded,training_labels,epochs=num_epochs,verbose=2)

"""## Salve o Modelo"""

#use o método save()
model.save('Text_Emotion.h5')

"""## Teste o modelo"""

#use o método predict() para previsão do modelo
#{"raiva": 0, "medo": 1, "alegria": 2, "amor": 3, "tristeza": 4, "surpresa": 5}

sentece = ["Eu estou feliz em encontrar meus amigos, Estamos planejando ir a uma festa.",
           "Eu tive um dia ruim na escola. Eu me machuquei jogando futebol."]

sequences = tokenizer.texts_to_sequences(sentence)

padded = pad_sequences(sequences,maxlen=max_length,padding=padding_type,truncating=trunc_type)

result = model.predict(padded)

predict_class = np.argmax(result,axis=1)
predict_class